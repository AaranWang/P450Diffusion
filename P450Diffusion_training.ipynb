{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# 设置环境中多张显卡可见\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0,1,2,3,4,5,6,7\"\n",
    "\n",
    "# 检测显卡是否可用\n",
    "if torch.cuda.is_available():\n",
    "    logging.warning(\"cuda is available!\")\n",
    "    # 判断环境中多少个显卡。如果大于1就输出显卡个数\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        logging.warning(f\"find{torch.cuda.device_count()}GPUS!\")\n",
    "    else:\n",
    "        logging.warning(\"it is only one GPU!\")\n",
    "else:\n",
    "    logging.warning(\"cuda is not available,exit!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import *\n",
    "from modules import UNet\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# logging 模块是 Python 内置的标准模块，主要用于输出运行日志\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%H:%M:%S\")\n",
    "\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, protein_high=560, protein_width=8, device=\"cuda\"):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.protein_high = protein_high\n",
    "        self.protein_width = protein_width\n",
    "        self.device = device\n",
    "\n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)   \n",
    "\n",
    "    def prepare_noise_schedule(self):\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "    # 对编码之后的蛋白质进行噪音处理\n",
    "    def noise_proteins(self, x, t):\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]     \n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1. - self.alpha_hat[t])[:, None, None, None]  \n",
    "        ε = torch.randn_like(x)    \n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * ε, ε\n",
    "\n",
    "    # 采样间隔，生成 n 个值在 1 ~ noise_steps 之间的数字，代表每条序列的采样次数，即加多少步噪音\n",
    "    def sample_timesteps(self, n):\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "\n",
    "    # 采样，输出模型 model 和 要采样序列的数量 n\n",
    "    def sample(self, model, n):\n",
    "        logging.info(f\"Sampling {n} new sequences......\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n, 1, self.protein_high, self.protein_width)).to(self.device)   \n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):    \n",
    "                t = (torch.ones(n) * i).long().to(self.device)      \n",
    "                predicted_noise = model(x, t)      \n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        return x\n",
    "\n",
    "def train(args):\n",
    "    setup_logging(args.run_name)\n",
    "    device = args.device\n",
    "    dataloader = get_data(args)\n",
    "    model = UNet().to(device)\n",
    "    model = torch.nn.DataParallel(UNet().to(device))\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "\n",
    "    mse = nn.MSELoss()\n",
    "    diffusion = Diffusion(protein_high=args.protein_high, protein_width=args.protein_width, device=device)\n",
    "    logger = SummaryWriter(os.path.join(\"runs/\", args.run_name))\n",
    "    l = len(dataloader) \n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        logging.info(f\"Starting epoch {epoch}:\")\n",
    "        pbar = tqdm(dataloader)\n",
    "        for i, proteins in enumerate(pbar):\n",
    "            proteins = proteins.to(device)           \n",
    "            \n",
    "            t = diffusion.sample_timesteps(proteins.shape[0]).to(device)\n",
    "            x_t, noise = diffusion.noise_proteins(proteins, t)\n",
    "            x_t = x_t.type(torch.FloatTensor)\n",
    "            x_t = x_t.to(device)\n",
    "\n",
    "            noise = noise.type(torch.FloatTensor)\n",
    "            predicted_noise = model(x_t, t)\n",
    "            predicted_noise = predicted_noise.type(torch.FloatTensor)\n",
    "            \n",
    "            loss = mse(noise, predicted_noise)\n",
    "            loss = loss.type(torch.FloatTensor)\n",
    "            loss = loss.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix(MSE=loss.item())\n",
    "            logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
    "\n",
    "        sampled_proteins = diffusion.sample(model, n=proteins.shape[0])\n",
    "\n",
    "        save_sequence(sampled_proteins, os.path.join(\"results/\", args.run_name, f\"{epoch}.fasta\"))\n",
    "        torch.save(model.module.state_dict(), os.path.join(\"models/\", args.run_name, \"{0}.pt\".format(epoch)))\n",
    "    print(\"over!\")\n",
    "\n",
    "\n",
    "def launch():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_known_args()[0]\n",
    "    args.run_name = \"P450Diffusion\"\n",
    "    args.epochs = 500\n",
    "    args.batch_size = 64\n",
    "    args.protein_high = 560\n",
    "    args.protein_width = 8\n",
    "    args.dataset_path = \"dataset/P450_All_Plant_Sequences_datasets.fasta\"\n",
    "    args.device = \"cuda\"\n",
    "    args.lr = 2e-3\n",
    "    train(args)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
